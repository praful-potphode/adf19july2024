{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adf9pm"
		},
		"trigger1_properties_typeProperties_scope": {
			"type": "string",
			"defaultValue": "/subscriptions/e526ad88-d1ae-4400-b898-7d39b489e571/resourceGroups/rg-adf9pm/providers/Microsoft.Storage/storageAccounts/datalakegen2stage"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/df_groupby')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard2_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_groupby_rank_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "rank1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard2",
						"creditcard2 aggregate(groupBy(card_type),",
						"     TotalNoofCards = count(credit_card_number)) ~> aggregate1",
						"aggregate1 rank(desc(TotalNoofCards, true),",
						"     output(Rank as long)) ~> rank1",
						"rank1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ds_groupby_rank.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_joinsdemo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv",
								"type": "DatasetReference"
							},
							"name": "employeedata"
						},
						{
							"dataset": {
								"referenceName": "ds_designation_csv",
								"type": "DatasetReference"
							},
							"name": "designationdata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_employees_azureSqlTable",
								"type": "DatasetReference"
							},
							"name": "LoadInEMpTable"
						}
					],
					"transformations": [
						{
							"name": "joinEmployeeAndDesignation"
						},
						{
							"name": "selectColumns"
						},
						{
							"name": "surrogateKey1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          emp_id as integer,",
						"          name as string,",
						"          age as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeedata",
						"source(output(",
						"          emp_id as integer,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> designationdata",
						"employeedata, designationdata join(employeedata@emp_id == designationdata@emp_id,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinEmployeeAndDesignation",
						"joinEmployeeAndDesignation select(mapColumn(",
						"          emp_id = employeedata@emp_id,",
						"          name,",
						"          age,",
						"          designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectColumns",
						"selectColumns keyGenerate(output(skey as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          emp_id as integer,",
						"          name as string,",
						"          age as integer,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> LoadInEMpTable"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_load_factsales')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_factsales_csv",
								"type": "DatasetReference"
							},
							"name": "factsalescsv"
						},
						{
							"dataset": {
								"referenceName": "dimdepartment_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimdepartment"
						},
						{
							"dataset": {
								"referenceName": "dimemployees_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimemployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_factsales_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "loadfactsales"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "removedepartmentnamecolumn"
						},
						{
							"name": "join2"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          orderid as string,",
						"          employee_name as string,",
						"          department_name as string,",
						"          sales as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> factsalescsv",
						"source(output(",
						"          skey as integer,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimdepartment",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimemployees",
						"factsalescsv, dimdepartment join(factsalescsv@department_name == dimdepartment@department_name,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          orderid,",
						"          employee_name,",
						"          sales,",
						"          department_id = skey",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removedepartmentnamecolumn",
						"removedepartmentnamecolumn, dimemployees join(employee_name == name,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join2 select(mapColumn(",
						"          orderid,",
						"          sales,",
						"          department_id,",
						"          empid",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          orderid as integer,",
						"          empid as integer,",
						"          department_id as integer,",
						"          sales as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> loadfactsales"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_pivot_xlsx",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_pivot_csv",
								"type": "DatasetReference"
							},
							"name": "pivotcsv"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Month as string,",
						"          Sales as integer,",
						"          Year as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 pivot(groupBy(Year),",
						"     pivotBy(Month),",
						"     Sales_ = sum(Sales),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> pivotcsv"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scdtype1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv_scd",
								"type": "DatasetReference"
							},
							"name": "employeecsv"
						},
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimemployee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "InsertRecords"
						},
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "UpdateRecordsInDB"
						}
					],
					"transformations": [
						{
							"name": "newrecords"
						},
						{
							"name": "UpdateRecords"
						},
						{
							"name": "lookup1"
						},
						{
							"name": "select1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeecsv",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimemployee",
						"employeecsv, dimemployee exists(employeecsv@empid == dimemployee@empid",
						"     && employeecsv@name == dimemployee@name,",
						"     negate:true,",
						"     broadcast: 'auto')~> newrecords",
						"dimemployee, employeecsv exists(employeecsv@empid==dimemployee@empid &&\r",
						"employeecsv@name==dimemployee@name &&\r",
						"dimemployee@designation!=employeecsv@designation,",
						"     negate:false,",
						"     broadcast: 'both')~> UpdateRecords",
						"UpdateRecords, employeecsv lookup(dimemployee@empid == employeecsv@empid",
						"     && dimemployee@name == employeecsv@name,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 select(mapColumn(",
						"          empid = employeecsv@empid,",
						"          name = employeecsv@name,",
						"          designation = employeecsv@designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 alterRow(updateIf(true())) ~> alterRow1",
						"newrecords sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> InsertRecords",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:true,",
						"     keys:['empid','name'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          designation",
						"     )) ~> UpdateRecordsInDB"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scdtype2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv_scd",
								"type": "DatasetReference"
							},
							"name": "employeecsv"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "azsqldimemployeescd2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "InsertNewrecords"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "insertoldrecordsnewvalues"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "updateoldrecords"
						}
					],
					"transformations": [
						{
							"name": "CreateAuditCOlumns"
						},
						{
							"name": "exists1"
						},
						{
							"name": "join1"
						},
						{
							"name": "selectcsvcolumns"
						},
						{
							"name": "updateauditcolumnsforactive"
						},
						{
							"name": "selectazsqlcolumns"
						},
						{
							"name": "updateauditcolumnsforinactive"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeecsv",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> azsqldimemployeescd2",
						"exists1 derive(startdate = currentDate(),",
						"          enddate = '',",
						"          iscurrent = 1) ~> CreateAuditCOlumns",
						"employeecsv, azsqldimemployeescd2 exists(employeecsv@empid == azsqldimemployeescd2@empid",
						"     && employeecsv@name == azsqldimemployeescd2@name,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"azsqldimemployeescd2, employeecsv join(azsqldimemployeescd2@empid == employeecsv@empid",
						"     && azsqldimemployeescd2@name == employeecsv@name,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          startdate,",
						"          enddate,",
						"          iscurrent,",
						"          empid = employeecsv@empid,",
						"          name = employeecsv@name,",
						"          designation = employeecsv@designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectcsvcolumns",
						"selectcsvcolumns derive(startdate = addDays(currentDate(), 1)) ~> updateauditcolumnsforactive",
						"join1 select(mapColumn(",
						"          empid = azsqldimemployeescd2@empid,",
						"          name = azsqldimemployeescd2@name,",
						"          designation = azsqldimemployeescd2@designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent,",
						"          skey",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectazsqlcolumns",
						"selectazsqlcolumns derive(enddate = currentDate(),",
						"          iscurrent = 0) ~> updateauditcolumnsforinactive",
						"updateauditcolumnsforinactive alterRow(updateIf(true())) ~> alterRow1",
						"CreateAuditCOlumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> InsertNewrecords",
						"updateauditcolumnsforactive sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent",
						"     )) ~> insertoldrecordsnewvalues",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['empid','skey','name','designation'],",
						"     skipKeyWrites:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          skey,",
						"          empid,",
						"          name,",
						"          designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent",
						"     )) ~> updateoldrecords"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard2_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard2"
						},
						{
							"dataset": {
								"referenceName": "ds_creditcard_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_union_creditcard_json",
								"type": "DatasetReference"
							},
							"name": "unionjson"
						}
					],
					"transformations": [
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard2",
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard3",
						"creditcard2, creditcard3 union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ds_union_creditcard.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> unionjson"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_dataflow')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_filter",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_dataflow_conditionalsplit')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "conditonal split demo",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_conditional_split",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {
										"filename": "CreditCardData3.csv"
									},
									"visa": {},
									"mastercard": {},
									"americanexpress": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_dataflow_groupby_rank')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "groupby and rank demo",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_groupby",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"creditcard2": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_groupby')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_dataflow_joins')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow joins",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_joinsdemo",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"employeedata": {},
									"designationdata": {},
									"LoadInEMpTable": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_joinsdemo')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_dataflow_union')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "union demo",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_union",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"creditcard2": {},
									"creditcard3": {
										"filename": "CreditCardData3.csv"
									},
									"unionjson": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_union')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_loadfactsales')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Load Fact Sales",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_load_factsales",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"factsalescsv": {},
									"dimdepartment": {},
									"dimemployees": {},
									"loadfactsales": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_load_factsales')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_onprem_sql_to_json')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlServerSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "ds_orders1_SqlServerTable",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "ds_json_orders1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_pivot_exists')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "exists",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_exists",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"intersecttable1": {},
									"intersecttable2": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "pivot",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_pivot",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"pivotcsv": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_pivot')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_scd_type1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_scdtype1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"employeecsv": {},
									"dimemployee": {},
									"InsertRecords": {},
									"UpdateRecordsInDB": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_scdtype1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_scd_type2')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "SCD 2 flow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "df_scdtype2",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"employeecsv": {},
									"azsqldimemployeescd2": {},
									"InsertNewrecords": {},
									"insertoldrecordsnewvalues": {},
									"updateoldrecords": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/df_scdtype2')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/trigger1')]",
			"type": "Microsoft.DataFactory/factories/triggers",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"runtimeState": "Started",
				"pipelines": [
					{
						"pipelineReference": {
							"referenceName": "pl_load_dimensions_facts_usp",
							"type": "PipelineReference"
						},
						"parameters": {}
					}
				],
				"type": "BlobEventsTrigger",
				"typeProperties": {
					"blobPathBeginsWith": "/input/blobs/FactSales/",
					"blobPathEndsWith": ".csv",
					"ignoreEmptyBlobs": true,
					"scope": "[parameters('trigger1_properties_typeProperties_scope')]",
					"events": [
						"Microsoft.Storage.BlobCreated"
					]
				}
			},
			"dependsOn": []
		}
	]
}