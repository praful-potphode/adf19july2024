{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adf9pm"
		},
		"SqlServer1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'SqlServer1'"
		},
		"ls_Oracle_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ls_Oracle'"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/SqlServer1')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "SqlServer",
				"typeProperties": {
					"connectionString": "[parameters('SqlServer1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "selfhosted",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ls_Oracle')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "Oracle",
				"typeProperties": {
					"connectionString": "[parameters('ls_Oracle_connectionString')]"
				},
				"connectVia": {
					"referenceName": "selfhosted",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_hr_employees_Avro')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Avro",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "hr_employees.avro",
						"folderPath": "AVRO",
						"fileSystem": "output"
					}
				},
				"schema": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "ds_transaction_csv",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "sd_transaction_json",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pl_load_dimensions_facts_usp')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "this pipeline loads the data in dimensions and facts using stored procedures",
				"activities": [
					{
						"name": "Copy data from csv to staging table",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Get File name from Factsales folder",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "AzureSqlSink",
								"preCopyScript": "truncate table staging.sales;",
								"writeBehavior": "insert",
								"sqlWriterUseTableLock": false,
								"disableMetricsCollection": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "ds_factsales_csv",
								"type": "DatasetReference",
								"parameters": {
									"filename": {
										"value": "@activity('Get File name from Factsales folder').output.childItems[0].name",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "ds_staging_sales_AzureSqlTable",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Load DIm Department",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Copy data from csv to staging table",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[usp_load_department_table]"
						},
						"linkedServiceName": {
							"referenceName": "ls_AzureSqlDatabase",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Load DimEmployee SCD2",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Load DIm Department",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[load_dimemployee_scd2]"
						},
						"linkedServiceName": {
							"referenceName": "ls_AzureSqlDatabase",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Load FactSales",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Load DimEmployee SCD2",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[load_factsales]"
						},
						"linkedServiceName": {
							"referenceName": "ls_AzureSqlDatabase",
							"type": "LinkedServiceReference"
						}
					},
					{
						"name": "Get File name from Factsales folder",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ds_FactSales_Folder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "Delete1",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Load FactSales",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ds_FactSales_Folder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"wildcardFileName": {
									"value": "@activity('Get File name from Factsales folder').output.childItems[0].name",
									"type": "Expression"
								},
								"enablePartitionDiscovery": false
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_orders1_SqlServerTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_SqlServer_localhost",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "OrderID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "CustomerID",
						"type": "nchar"
					},
					{
						"name": "EmployeeID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "OrderDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "RequiredDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "ShippedDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "ShipVia",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Freight",
						"type": "money",
						"precision": 19,
						"scale": 4
					},
					{
						"name": "ShipName",
						"type": "nvarchar"
					},
					{
						"name": "ShipAddress",
						"type": "nvarchar"
					},
					{
						"name": "ShipCity",
						"type": "nvarchar"
					},
					{
						"name": "ShipRegion",
						"type": "nvarchar"
					},
					{
						"name": "ShipPostalCode",
						"type": "nvarchar"
					},
					{
						"name": "ShipCountry",
						"type": "nvarchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "orders1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_conditional_split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard_csv",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_visa_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "visa"
						},
						{
							"dataset": {
								"referenceName": "ds_mastercard_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "mastercard"
						},
						{
							"dataset": {
								"referenceName": "ds_america_express_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "americanexpress"
						}
					],
					"transformations": [
						{
							"name": "selectcolumns"
						},
						{
							"name": "cast1"
						},
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          credit_card_number,",
						"          expiration_date,",
						"          cvv,",
						"          card_holder_name,",
						"          card_type,",
						"          credit_limit,",
						"          available_credit",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectcolumns",
						"selectcolumns cast(output(",
						"          credit_card_number as long '000,000,000',",
						"          expiration_date as date 'MM/dd/yyyy',",
						"          cvv as integer,",
						"          credit_limit as double,",
						"          available_credit as double",
						"     ),",
						"     errors: true) ~> cast1",
						"cast1 split(card_type=='Visa',",
						"     card_type=='Mastercard',",
						"     disjoint: false) ~> split1@(visa, mastercard, americanexpress)",
						"split1@visa sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> visa",
						"split1@mastercard sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> mastercard",
						"split1@americanexpress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> americanexpress"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_exists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_intersect_table1_csv",
								"type": "DatasetReference"
							},
							"name": "intersecttable1"
						},
						{
							"dataset": {
								"referenceName": "ds_intersect_table2_csv",
								"type": "DatasetReference"
							},
							"name": "intersecttable2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_exists_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          country as string,",
						"          state as string,",
						"          count as string,",
						"          total as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> intersecttable1",
						"source(output(",
						"          country as string,",
						"          state as string,",
						"          count as string,",
						"          total as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> intersecttable2",
						"intersecttable1, intersecttable2 exists(intersecttable1@country == intersecttable2@country",
						"     && intersecttable1@state == intersecttable2@state",
						"     && intersecttable1@count == intersecttable2@count",
						"     && intersecttable1@total == intersecttable2@total,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_filter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard_csv",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "ds_creditcard_csv",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_creditcard_type_json",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "ds_creditcard_type_json",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						},
						{
							"name": "select1"
						},
						{
							"name": "select2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 filter(card_type=='Visa' && !isNull(billing_state)) ~> filter1",
						"filter1 select(mapColumn(",
						"          credit_card_number,",
						"          expiration_date,",
						"          cvv,",
						"          card_type,",
						"          credit_limit,",
						"          available_credit",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"source2 select(mapColumn(",
						"          credit_card_number,",
						"          expiration_date,",
						"          cvv,",
						"          card_holder_name",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[(concat(toString(currentTimestamp()), '.json'))],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['output2.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_groupby')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard2_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_groupby_rank_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "rank1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard2",
						"creditcard2 aggregate(groupBy(card_type),",
						"     TotalNoofCards = count(credit_card_number)) ~> aggregate1",
						"aggregate1 rank(desc(TotalNoofCards, true),",
						"     output(Rank as long)) ~> rank1",
						"rank1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ds_groupby_rank.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_joinsdemo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv",
								"type": "DatasetReference"
							},
							"name": "employeedata"
						},
						{
							"dataset": {
								"referenceName": "ds_designation_csv",
								"type": "DatasetReference"
							},
							"name": "designationdata"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_employees_azureSqlTable",
								"type": "DatasetReference"
							},
							"name": "LoadInEMpTable"
						}
					],
					"transformations": [
						{
							"name": "joinEmployeeAndDesignation"
						},
						{
							"name": "selectColumns"
						},
						{
							"name": "surrogateKey1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          emp_id as integer,",
						"          name as string,",
						"          age as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeedata",
						"source(output(",
						"          emp_id as integer,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> designationdata",
						"employeedata, designationdata join(employeedata@emp_id == designationdata@emp_id,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinEmployeeAndDesignation",
						"joinEmployeeAndDesignation select(mapColumn(",
						"          emp_id = employeedata@emp_id,",
						"          name,",
						"          age,",
						"          designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectColumns",
						"selectColumns keyGenerate(output(skey as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          emp_id as integer,",
						"          name as string,",
						"          age as integer,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> LoadInEMpTable"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_load_factsales')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_factsales_csv",
								"type": "DatasetReference"
							},
							"name": "factsalescsv"
						},
						{
							"dataset": {
								"referenceName": "dimdepartment_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimdepartment"
						},
						{
							"dataset": {
								"referenceName": "dimemployees_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimemployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_factsales_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "loadfactsales"
						}
					],
					"transformations": [
						{
							"name": "join1"
						},
						{
							"name": "removedepartmentnamecolumn"
						},
						{
							"name": "join2"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          orderid as string,",
						"          employee_name as string,",
						"          department_name as string,",
						"          sales as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> factsalescsv",
						"source(output(",
						"          skey as integer,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimdepartment",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimemployees",
						"factsalescsv, dimdepartment join(factsalescsv@department_name == dimdepartment@department_name,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          orderid,",
						"          employee_name,",
						"          sales,",
						"          department_id = skey",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> removedepartmentnamecolumn",
						"removedepartmentnamecolumn, dimemployees join(employee_name == name,",
						"     joinType:'left',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join2",
						"join2 select(mapColumn(",
						"          orderid,",
						"          sales,",
						"          department_id,",
						"          empid",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          orderid as integer,",
						"          empid as integer,",
						"          department_id as integer,",
						"          sales as decimal(19,4)",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> loadfactsales"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_pivot_xlsx",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_pivot_csv",
								"type": "DatasetReference"
							},
							"name": "pivotcsv"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Month as string,",
						"          Sales as integer,",
						"          Year as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 pivot(groupBy(Year),",
						"     pivotBy(Month),",
						"     Sales_ = sum(Sales),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> pivotcsv"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scdtype1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv_scd",
								"type": "DatasetReference"
							},
							"name": "employeecsv"
						},
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "dimemployee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "InsertRecords"
						},
						{
							"dataset": {
								"referenceName": "ds_dimeployee_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "UpdateRecordsInDB"
						}
					],
					"transformations": [
						{
							"name": "newrecords"
						},
						{
							"name": "UpdateRecords"
						},
						{
							"name": "lookup1"
						},
						{
							"name": "select1"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeecsv",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dimemployee",
						"employeecsv, dimemployee exists(employeecsv@empid == dimemployee@empid",
						"     && employeecsv@name == dimemployee@name,",
						"     negate:true,",
						"     broadcast: 'auto')~> newrecords",
						"dimemployee, employeecsv exists(employeecsv@empid==dimemployee@empid &&\r",
						"employeecsv@name==dimemployee@name &&\r",
						"dimemployee@designation!=employeecsv@designation,",
						"     negate:false,",
						"     broadcast: 'both')~> UpdateRecords",
						"UpdateRecords, employeecsv lookup(dimemployee@empid == employeecsv@empid",
						"     && dimemployee@name == employeecsv@name,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 select(mapColumn(",
						"          empid = employeecsv@empid,",
						"          name = employeecsv@name,",
						"          designation = employeecsv@designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 alterRow(updateIf(true())) ~> alterRow1",
						"newrecords sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> InsertRecords",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:true,",
						"     keys:['empid','name'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          designation",
						"     )) ~> UpdateRecordsInDB"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scdtype2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata_csv_scd",
								"type": "DatasetReference"
							},
							"name": "employeecsv"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "azsqldimemployeescd2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "InsertNewrecords"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "insertoldrecordsnewvalues"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_AzureSqlTable",
								"type": "DatasetReference"
							},
							"name": "updateoldrecords"
						}
					],
					"transformations": [
						{
							"name": "CreateAuditCOlumns"
						},
						{
							"name": "exists1"
						},
						{
							"name": "join1"
						},
						{
							"name": "selectcsvcolumns"
						},
						{
							"name": "updateauditcolumnsforactive"
						},
						{
							"name": "selectazsqlcolumns"
						},
						{
							"name": "updateauditcolumnsforinactive"
						},
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          designation as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeecsv",
						"source(output(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> azsqldimemployeescd2",
						"exists1 derive(startdate = currentDate(),",
						"          enddate = '',",
						"          iscurrent = 1) ~> CreateAuditCOlumns",
						"employeecsv, azsqldimemployeescd2 exists(employeecsv@empid == azsqldimemployeescd2@empid",
						"     && employeecsv@name == azsqldimemployeescd2@name,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"azsqldimemployeescd2, employeecsv join(azsqldimemployeescd2@empid == employeecsv@empid",
						"     && azsqldimemployeescd2@name == employeecsv@name,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          startdate,",
						"          enddate,",
						"          iscurrent,",
						"          empid = employeecsv@empid,",
						"          name = employeecsv@name,",
						"          designation = employeecsv@designation",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectcsvcolumns",
						"selectcsvcolumns derive(startdate = addDays(currentDate(), 1)) ~> updateauditcolumnsforactive",
						"join1 select(mapColumn(",
						"          empid = azsqldimemployeescd2@empid,",
						"          name = azsqldimemployeescd2@name,",
						"          designation = azsqldimemployeescd2@designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent,",
						"          skey",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectazsqlcolumns",
						"selectazsqlcolumns derive(enddate = currentDate(),",
						"          iscurrent = 0) ~> updateauditcolumnsforinactive",
						"updateauditcolumnsforinactive alterRow(updateIf(true())) ~> alterRow1",
						"CreateAuditCOlumns sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> InsertNewrecords",
						"updateauditcolumnsforactive sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent",
						"     )) ~> insertoldrecordsnewvalues",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          skey as integer,",
						"          empid as integer,",
						"          name as string,",
						"          designation as string,",
						"          startdate as date,",
						"          enddate as date,",
						"          iscurrent as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['empid','skey','name','designation'],",
						"     skipKeyWrites:true,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          skey,",
						"          empid,",
						"          name,",
						"          designation,",
						"          startdate,",
						"          enddate,",
						"          iscurrent",
						"     )) ~> updateoldrecords"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_creditcard2_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard2"
						},
						{
							"dataset": {
								"referenceName": "ds_creditcard_csv",
								"type": "DatasetReference"
							},
							"name": "creditcard3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_union_creditcard_json",
								"type": "DatasetReference"
							},
							"name": "unionjson"
						}
					],
					"transformations": [
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard2",
						"source(output(",
						"          credit_card_number as string,",
						"          expiration_date as string,",
						"          cvv as string,",
						"          card_holder_name as string,",
						"          billing_address as string,",
						"          billing_city as string,",
						"          billing_state as string,",
						"          billing_zip_code as string,",
						"          card_type as string,",
						"          credit_limit as string,",
						"          available_credit as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> creditcard3",
						"creditcard2, creditcard3 union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ds_union_creditcard.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> unionjson"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_onprem_salesorderheader')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_onprem_SqlServer",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "SalesOrderID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "RevisionNumber",
						"type": "tinyint",
						"precision": 3
					},
					{
						"name": "OrderDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "DueDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "ShipDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					},
					{
						"name": "Status",
						"type": "tinyint",
						"precision": 3
					},
					{
						"name": "OnlineOrderFlag",
						"type": "bit"
					},
					{
						"name": "SalesOrderNumber",
						"type": "nvarchar"
					},
					{
						"name": "PurchaseOrderNumber",
						"type": "nvarchar"
					},
					{
						"name": "AccountNumber",
						"type": "nvarchar"
					},
					{
						"name": "CustomerID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SalesPersonID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "TerritoryID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "BillToAddressID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "ShipToAddressID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "ShipMethodID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "CreditCardID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "CreditCardApprovalCode",
						"type": "varchar"
					},
					{
						"name": "CurrencyRateID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "SubTotal",
						"type": "money",
						"precision": 19,
						"scale": 4
					},
					{
						"name": "TaxAmt",
						"type": "money",
						"precision": 19,
						"scale": 4
					},
					{
						"name": "Freight",
						"type": "money",
						"precision": 19,
						"scale": 4
					},
					{
						"name": "TotalDue",
						"type": "money",
						"precision": 19,
						"scale": 4
					},
					{
						"name": "Comment",
						"type": "nvarchar"
					},
					{
						"name": "rowguid",
						"type": "uniqueidentifier"
					},
					{
						"name": "ModifiedDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"schema": "Sales",
					"table": "SalesOrderHeader"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_salesorderheader_parquet_to_parquet')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_salesorderheader_Parquet1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_transformed_Parquet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          SalesOrderID as integer,",
						"          RevisionNumber as integer,",
						"          OrderDate as timestamp,",
						"          DueDate as timestamp,",
						"          ShipDate as timestamp,",
						"          Status as integer,",
						"          OnlineOrderFlag as boolean,",
						"          SalesOrderNumber as string,",
						"          PurchaseOrderNumber as string,",
						"          AccountNumber as string,",
						"          CustomerID as integer,",
						"          SalesPersonID as integer,",
						"          TerritoryID as integer,",
						"          BillToAddressID as integer,",
						"          ShipToAddressID as integer,",
						"          ShipMethodID as integer,",
						"          CreditCardID as integer,",
						"          CreditCardApprovalCode as string,",
						"          CurrencyRateID as integer,",
						"          SubTotal as decimal(19,4),",
						"          TaxAmt as decimal(19,4),",
						"          Freight as decimal(19,4),",
						"          TotalDue as decimal(19,4),",
						"          Comment as string,",
						"          rowguid as string,",
						"          ModifiedDate as timestamp",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     format: 'parquet') ~> source1",
						"source1 select(mapColumn(",
						"          SalesOrderID,",
						"          RevisionNumber,",
						"          OrderDate,",
						"          ShipDate,",
						"          SalesOrderNumber,",
						"          SubTotal,",
						"          TaxAmt,",
						"          Freight,",
						"          TotalDue",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     format: 'parquet',",
						"     partitionFileNames:['salesorderheader_tranformed.parquet'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_transformed_SqlServerTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "SqlServer1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "salesorderheader_transformed"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/SqlServer1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/OracleTable1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_Oracle",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "OracleTable",
				"schema": [],
				"typeProperties": {
					"schema": "HR",
					"table": "EMPLOYEES"
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/ls_Oracle')]"
			]
		}
	]
}